## Training model from 0 to 0.025 ##
## Training initial conditions ##
Loss: 174.413
Loss: 70.1175
Loss: 16.1194
Loss: 6.06843
Loss: 3.12595
Loss: 2.28132
Loss: 1.88511
Loss: 1.67946
Loss: 1.54081
Loss: 1.35531
Loss: 1.2975
Loss: 1.14752
Loss: 1.08713
Loss: 1.00674
Loss: 0.910992
Loss: 0.832301
Loss: 0.745645
Loss: 0.676892
Loss: 0.625068
Loss: 0.599778
## Training physics ##
Loss: 5114.94
Loss: 3462.76
Loss: 1993.03
Loss: 1410.19
Loss: 1111.29
Loss: 918.209
Loss: 767.502
Loss: 708.535
Loss: 619.337
Loss: 519.5
Loss: 468.916
Loss: 404.236
Loss: 367.045
Loss: 333.062
Loss: 310.702
Loss: 282.297
Loss: 259.228
Loss: 240.607
Loss: 222.121
Loss: 214.705

## Training model from 0.025 to 0.05 ##
## Training initial conditions ##
Loss: 476.548
Loss: 339.776
Loss: 268.283
Loss: 222.403
Loss: 183.964
Loss: 149.525
Loss: 125.695
Loss: 107.318
Loss: 88.2895
Loss: 76.3998
Loss: 65.1959
Loss: 53.7287
Loss: 45.2575
Loss: 38.1413
Loss: 32.8882
Loss: 27.9075
Loss: 23.6567
Loss: 19.8749
Loss: 17.1775
Loss: 14.1099
## Training physics ##
Loss: 1808.55
Loss: 1222.95
Loss: 837.173
Loss: 621.799
Loss: 503.258
Loss: 436.139
Loss: 368.984
Loss: 318.179
Loss: 272.732
Loss: 243.54
Loss: 210.687
Loss: 186.833
Loss: 168.937
Loss: 153.094
Loss: 144.542
Loss: 137.589
Loss: 126.887
Loss: 116.656
Loss: 112.23
Loss: 106.126

## Training model from 0.05 to 0.075 ##
## Training initial conditions ##
Loss: 983.128
Loss: 805.665
Loss: 677.408
Loss: 564.442
Loss: 473.356
Loss: 402.327
Loss: 338.513
Loss: 298.692
Loss: 259.004
Loss: 219.785
Loss: 184.925
Loss: 160.391
Loss: 137.127
Loss: 115.728
Loss: 98.177
Loss: 84.0374
Loss: 71.9481
Loss: 61.3671
Loss: 53.6991
Loss: 46.4581
## Training physics ##
Loss: 1217.41
Loss: 621.091
Loss: 480.983
Loss: 362.746
Loss: 289.631
Loss: 247.177
Loss: 209.953
Loss: 189.675
Loss: 164.952
Loss: 145.356
Loss: 135.269
Loss: 118.459
Loss: 106.552
Loss: 99.649
Loss: 92.1592
Loss: 84.1342
Loss: 78.18
Loss: 75.0756
Loss: 69.9783
Loss: 66.2346

## Training model from 0.075 to 0.1 ##
## Training initial conditions ##
Loss: 1230.59
Loss: 1016.41
Loss: 866.826
Loss: 739.895
Loss: 620.602
Loss: 523.761
Loss: 439.308
Loss: 365.614
Loss: 316.053
Loss: 272.464
Loss: 226.815
Loss: 190.496
Loss: 165.485
Loss: 137.598
Loss: 114.006
Loss: 97.4557
Loss: 79.9747
Loss: 68.2646
Loss: 58.1403
Loss: 49.8858
## Training physics ##
Loss: 674.602
Loss: 346.844
Loss: 262.679
Loss: 198.302
Loss: 151.351
Loss: 130.436
Loss: 113.363
Loss: 103.128
Loss: 92.4572
Loss: 83.423
Loss: 78.4978
Loss: 71.2957
Loss: 68.8125
Loss: 60.8374
Loss: 57.2051
Loss: 54.2871
Loss: 51.9195
Loss: 48.8269
Loss: 48.2462
Loss: 45.5143

Time to train models: 15781870 us
generation,cost
0,89095.2
1,82940.6
2,77322.8
3,72706.2
4,69632.6
Time to G.A. optimization using Pimodels: 1993558 us
generation,cost
0,3.31713e+06
1,2.22984e+06
2,1.85875e+06
3,1.71619e+06
4,1.62743e+06
5,1.55195e+06
Time to G.A. optimization using Explicit integration: 39281531 us
Random solution: 
t,x,xDot,xDotDot
0,0,200,-59334.7
0.0002,0.038881,189.126,-49827.9
0.000432026,0.0815022,178.576,-41524.5
0.000677424,0.124144,169.225,-35008.4
0.000939985,0.167434,160.747,-29835.1
0.00122202,0.211641,152.943,-25709.1
0.00152639,0.257058,145.647,-22394.5
0.00185645,0.303962,138.72,-19706.4
0.00221609,0.352628,132.048,-17500.4
0.00260986,0.403318,125.534,-15664.2
0.00304301,0.456275,119.1,-14110.8
0.00351873,0.51139,112.717,-12779.9
0.00403428,0.567857,106.434,-11634.8
0.00459766,0.626029,100.174,-10622.6
0.00521683,0.686079,93.889,-9707.9
0.00590101,0.748113,87.5437,-8865.28
0.00666038,0.812114,81.1194,-8076.8
0.00750569,0.877891,74.6158,-7330.49
0.00844749,0.945023,68.0554,-6619.2
0.0094951,1.01282,61.4859,-5939.76
0.0106348,1.07918,55.0883,-5302.82
0.0118231,1.14103,49.1369,-4727.39
0.0130782,1.19913,43.5432,-4198.14
0.0144135,1.25368,38.2727,-3707.35
0.0158422,1.30474,33.3099,-3250.45
0.0173784,1.35224,28.6514,-2824.97
0.0190367,1.39606,24.3029,-2429.9
0.0208316,1.43597,20.2774,-2065.4
0.022776,1.47171,16.5946,-1732.57
0.0248767,1.50298,13.2794,-1433.24
0.0271292,1.52949,10.3581,-1169.51
0.0295132,1.55109,7.84964,-942.978
0.031994,1.56786,5.75405,-753.573
0.0344747,1.57998,4.07959,-602.051
0.0358687,1.58511,3.29113,-530.611
0.0376702,1.59022,2.40925,-450.617
0.0396871,1.59422,1.57879,-375.165
0.0409244,1.5959,1.13979,-335.204
0.0424484,1.59726,0.662832,-291.722
0.0443168,1.59802,0.161744,-245.937
0.0459512,1.59797,-0.211569,-211.732
0.0476516,1.59732,-0.544898,-181.096
0.0494173,1.59609,-0.839975,-153.875
0.0512431,1.59431,-1.09846,-129.923
0.053069,1.5921,-1.31661,-109.598
0.0546184,1.58994,-1.47468,-94.7815
0.0562434,1.58742,-1.61748,-81.3097
0.058051,1.58437,-1.75253,-68.4679
0.0599391,1.58095,-1.87077,-57.1087
0.0614112,1.57814,-1.94911,-49.4948
0.063033,1.57491,-2.02332,-42.1979
0.0649153,1.57103,-2.09574,-34.9652
0.0666082,1.56744,-2.15012,-29.4275
0.0683656,1.56362,-2.19739,-24.5072
0.070123,1.55972,-2.23666,-20.3082
0.0718803,1.55576,-2.26911,-16.725
0.0734258,1.55223,-2.2928,-14.0074
0.0749712,1.54868,-2.31258,-11.6446
0.0767508,1.54454,-2.33116,-9.30482
0.0786923,1.54,-2.34706,-7.15014
0.0800944,1.5367,-2.35612,-5.80724
0.0817104,1.53289,-2.36439,-4.46057
0.0836625,1.52827,-2.3717,-3.07929
0.0853024,1.52437,-2.37592,-2.09182
0.0870402,1.52024,-2.37875,-1.19569
0.088778,1.51611,-2.38014,-0.431187
0.0905158,1.51197,-2.38029,0.220695
0.0922536,1.50783,-2.37941,0.776224
0.0939914,1.5037,-2.37762,1.24931
0.0955388,1.50002,-2.3754,1.61444
0.0970863,1.49635,-2.37264,1.92988
0.0988522,1.49216,-2.36895,2.23618
0.1,1.48944,-2.36628,2.41226
Pimodel-based best: 
t,x,xDot,xDotDot
0,0,200,-21588.2
0.0002,0.0395756,195.792,-20509.6
0.000488312,0.0951925,190.086,-19095.9
0.000786467,0.151039,184.592,-17781.8
0.00110167,0.208361,179.187,-16534.9
0.00143604,0.267374,173.859,-15356.4
0.00179248,0.328393,168.587,-14248.4
0.00217434,0.391757,163.349,-13214.1
0.00258562,0.45785,158.116,-12256.2
0.00303108,0.527098,152.858,-11375.5
0.00351645,0.599984,147.538,-10570.9
0.00404866,0.677045,142.113,-9838.89
0.00463615,0.758876,136.535,-9173.35
0.00528908,0.846115,130.75,-8566.03
0.00601969,0.939407,124.703,-8006.81
0.00684231,1.03934,118.337,-7484.38
0.00777334,1.14635,111.607,-6987.07
0.00883095,1.26057,104.479,-6503.77
0.0100349,1.38177,96.9433,-6024.89
0.0114078,1.50934,89.0092,-5542.97
0.012963,1.64126,80.7742,-5056.96
0.0147321,1.77651,72.2725,-4563.58
0.0167684,1.91458,63.5037,-4059.26
0.0190616,2.04998,54.7808,-3559.67
0.02167,2.18134,46.1552,-3066.34
0.0246635,2.30652,37.7189,-2583.8
0.0280813,2.42129,29.6981,-2124.55
0.0302894,2.48189,25.2916,-1871.92
0.0331193,2.54636,20.4022,-1591.23
0.0345661,2.57426,18.1932,-1464.19
0.0365499,2.60758,15.4482,-1306.16
0.0391286,2.64328,12.3184,-1125.67
0.0410635,2.66508,10.2578,-1006.57
0.043226,2.685,8.21182,-888.076
0.0455575,2.70184,6.27526,-775.625
0.0474117,2.71219,4.91198,-696.232
0.0494158,2.72069,3.59518,-619.333
0.0516687,2.72728,2.28803,-542.731
0.0539216,2.73112,1.14286,-475.339
0.055673,2.73242,0.351966,-428.592
0.0575734,2.73234,-0.418303,-382.872
0.0597441,2.73057,-1.19787,-336.353
0.062176,2.72671,-1.95896,-290.626
0.0647129,2.72085,-2.64245,-249.214
0.0665009,2.71574,-3.06458,-223.415
0.0685701,2.70894,-3.49863,-196.663
0.0710902,2.69953,-3.95734,-168.07
0.0731903,2.69086,-4.28793,-147.185
0.0754653,2.68075,-4.59957,-127.214
0.0777404,2.66997,-4.8686,-109.676
0.0800155,2.65862,-5.1002,-94.2756
0.0819664,2.6485,-5.27248,-82.5686
0.0840048,2.63759,-5.42945,-71.6573
0.0862926,2.62499,-5.58073,-60.8393
0.0887053,2.61136,-5.71519,-50.8716
0.090532,2.60084,-5.80189,-44.1822
0.0925803,2.58887,-5.88538,-37.4759
0.0950118,2.57445,-5.96779,-30.4806
0.0971132,2.56185,-6.02614,-25.1737
0.0993487,2.54832,-6.07672,-20.1946
0.1,2.54436,-6.08943,-18.8568
Explicit-based best: 
t,x,xDot,xDotDot
0,0,200,-13757.1
0.0002,0.0397234,197.228,-13926.6
0.000551829,0.108252,192.332,-13844.8
0.00091567,0.17732,187.353,-13495.7
0.00130878,0.249939,182.143,-13003.4
0.00173414,0.326257,176.73,-12446.9
0.00219722,0.406784,171.101,-11871.5
0.00270453,0.492082,165.226,-11300.7
0.00326422,0.582818,159.061,-10743.2
0.00388665,0.679778,152.547,-10198.8
0.00458521,0.783897,145.614,-9661.68
0.00537741,0.89628,138.178,-9123.11
0.00628653,1.01821,130.138,-8572.67
0.00734361,1.15109,121.385,-7999.19
0.00858959,1.29629,111.803,-7391.67
0.010076,1.45456,101.309,-6741.16
0.0117155,1.61189,90.7932,-6098.37
0.0135245,1.76651,80.3455,-5464.48
0.0155493,1.91843,69.9318,-4834.88
0.0178419,2.06662,59.5806,-4209.78
0.0204626,2.20904,49.3766,-3593.38
0.0234653,2.34204,39.5098,-2996.52
0.0254907,2.41616,33.7983,-2650.45
0.0281125,2.49613,27.3739,-2260.38
0.0294801,2.53151,24.4075,-2080.02
0.0313425,2.57349,20.7453,-1856.91
0.0338595,2.62012,16.4127,-1592.27
0.0354801,2.64469,13.9561,-1441.83
0.0375029,2.67009,11.2134,-1273.4
0.0399976,2.6943,8.2687,-1091.88
0.0414345,2.70508,6.76735,-999.017
0.0432804,2.71594,5.02494,-890.853
0.045745,2.72575,2.98966,-763.87
0.0473241,2.72955,1.84124,-691.844
0.049286,2.73188,0.564388,-611.341
0.051753,2.73151,-0.831713,-522.67
0.0533006,2.72961,-1.60188,-473.389
0.0551784,2.7258,-2.43917,-419.422
0.0578609,2.71784,-3.47163,-352.152
0.0595336,2.71155,-4.02942,-315.378
0.0617397,2.70193,-4.67649,-272.2
0.064116,2.69009,-5.27404,-231.672
0.0660575,2.67943,-5.69507,-202.61
0.0681964,2.66681,-6.09752,-174.293
0.0704661,2.65255,-6.4626,-147.982
0.0722707,2.64065,-6.71268,-129.501
0.0742392,2.6272,-6.94954,-111.51
0.0765028,2.6112,-7.1809,-93.3047
0.0787664,2.59472,-7.37376,-77.4336
0.0804606,2.58212,-7.4959,-66.9199
0.0823725,2.56767,-7.61348,-56.2816
0.0846969,2.54984,-7.73079,-44.9096
0.0866813,2.53441,-7.81132,-36.4085
0.088827,2.51757,-7.88057,-28.3087
0.0909726,2.50061,-7.93355,-21.2127
0.0931182,2.48354,-7.97228,-14.999
0.0949219,2.46914,-7.99512,-10.3915
0.0968295,2.45387,-8.01072,-6.04747
0.0990196,2.43632,-8.01906,-1.65766
0.1,2.42845,-8.01981,0.11235