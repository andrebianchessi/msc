## Training model from 0 to 0.02 ##
## Training initial conditions ##
Loss: 138.401
Loss: 98.5164
Loss: 84.4358
Loss: 79.8801
Loss: 76.6193
Loss: 73.9963
Loss: 70.6816
Loss: 68.5405
Loss: 64.0942
Loss: 59.8343
Loss: 57.3068
Loss: 55.7897
Loss: 52.6632
Loss: 50.635
Loss: 46.941
Loss: 43.9633
Loss: 42.4763
Loss: 40.193
Loss: 38.6151
Loss: 36.2205
## Training physics ##
Loss: 4670.95
Loss: 2659.68
Loss: 2160.72
Loss: 1922.8
Loss: 1728.16
Loss: 1582.6
Loss: 1435.31
Loss: 1349.83
Loss: 1262.5
Loss: 1196.53
Loss: 1130.17
Loss: 1104.14
Loss: 1027.28
Loss: 981.845
Loss: 945.012
Loss: 900.47
Loss: 867.959
Loss: 838.204
Loss: 803.281
Loss: 775.788

## Training model from 0.02 to 0.04 ##
## Training initial conditions ##
Loss: 245.077
Loss: 197.299
Loss: 172.031
Loss: 151.822
Loss: 129.06
Loss: 113.457
Loss: 99.3135
Loss: 86.7479
Loss: 76.9878
Loss: 66.3682
Loss: 59.8892
Loss: 52.9631
Loss: 47.5873
Loss: 42.8263
Loss: 38.7987
Loss: 35.959
Loss: 32.5593
Loss: 29.7858
Loss: 27.0581
Loss: 24.8265
## Training physics ##
Loss: 1121.46
Loss: 948.965
Loss: 883.955
Loss: 809.808
Loss: 785.748
Loss: 751.496
Loss: 721.117
Loss: 685.987
Loss: 650.79
Loss: 632.271
Loss: 619.872
Loss: 595.954
Loss: 580.317
Loss: 566.421
Loss: 547.418
Loss: 532.443
Loss: 520.775
Loss: 500.845
Loss: 490.949
Loss: 484.122

## Training model from 0.04 to 0.06 ##
## Training initial conditions ##
Loss: 464.89
Loss: 390.821
Loss: 325.91
Loss: 288.463
Loss: 244.247
Loss: 207.717
Loss: 180.071
Loss: 153.128
Loss: 131.389
Loss: 113.818
Loss: 96.1643
Loss: 80.8364
Loss: 70.0088
Loss: 60.7606
Loss: 52.9281
Loss: 46.8719
Loss: 40.7202
Loss: 35.6332
Loss: 31.0705
Loss: 26.9988
## Training physics ##
Loss: 529.365
Loss: 492.162
Loss: 466.9
Loss: 452.38
Loss: 435.445
Loss: 429.341
Loss: 398.829
Loss: 382.202
Loss: 366.21
Loss: 356.342
Loss: 342.516
Loss: 332.05
Loss: 324.457
Loss: 317.731
Loss: 310.123
Loss: 301.368
Loss: 293.688
Loss: 286.912
Loss: 273.128
Loss: 266.711

## Training model from 0.06 to 0.08 ##
## Training initial conditions ##
Loss: 565.107
Loss: 480.672
Loss: 395.816
Loss: 346.524
Loss: 298.082
Loss: 255.239
Loss: 213.31
Loss: 176.551
Loss: 152.987
Loss: 129.464
Loss: 108.714
Loss: 94.345
Loss: 81.3162
Loss: 70.6488
Loss: 60.5125
Loss: 52.7541
Loss: 43.8348
Loss: 37.9658
Loss: 32.4978
Loss: 28.0593
## Training physics ##
Loss: 270.268
Loss: 264.454
Loss: 251.411
Loss: 241.326
Loss: 232.758
Loss: 219.367
Loss: 212.388
Loss: 205.819
Loss: 199.771
Loss: 199.801
Loss: 188.083
Loss: 182.774
Loss: 178.258
Loss: 174.074
Loss: 168.257
Loss: 163.558
Loss: 161.092
Loss: 156.67
Loss: 154.272
Loss: 152.08

## Training model from 0.08 to 0.1 ##
## Training initial conditions ##
Loss: 615.775
Loss: 535.463
Loss: 465.659
Loss: 394.528
Loss: 332.35
Loss: 284.245
Loss: 243.907
Loss: 202.71
Loss: 177.379
Loss: 149.764
Loss: 126.28
Loss: 108.707
Loss: 93.0922
Loss: 78.1191
Loss: 65.886
Loss: 55.3261
Loss: 46.9243
Loss: 41.1975
Loss: 36.1576
Loss: 30.3279
## Training physics ##
Loss: 187.208
Loss: 173.545
Loss: 167.425
Loss: 161.113
Loss: 155.968
Loss: 151.342
Loss: 146.117
Loss: 141.301
Loss: 137.657
Loss: 134.64
Loss: 132.433
Loss: 128.685
Loss: 126.239
Loss: 123.615
Loss: 121.063
Loss: 119.291
Loss: 116.508
Loss: 113.503
Loss: 111.384
Loss: 110.077

Time to train models: 28542559 us
generation,cost
0,173899
1,163089
2,154040
3,149484
4,145658
5,142153
6,139197
7,135651
8,132633
9,130116
10,128154
11,126127
12,124135
13,122032
14,120195
15,118574
16,117342
17,116113
18,114763
19,113467
20,112310
21,111106
22,110025
Time to G.A. optimization using Pimodels: 14822418 us
generation,cost
0,3.78738e+06
1,2.47676e+06
2,2.10393e+06
3,1.89531e+06
4,1.76032e+06
5,1.6561e+06
6,1.56544e+06
7,1.4818e+06
8,1.41366e+06
9,1.35678e+06
10,1.31759e+06
11,1.28693e+06
12,1.26965e+06
13,1.25381e+06
14,1.24371e+06
Time to G.A. optimization using Explicit integration: 90198706 us
Random solution: 
t,x,xDot,xDotDot
0,0,200,-64443.6
0.0002,0.0387875,188.233,-53692
0.000437199,0.0820229,176.696,-44068.4
0.00068602,0.124708,166.706,-36611.4
0.000950228,0.167548,157.843,-30781.8
0.00123181,0.210837,149.85,-26222.7
0.00153323,0.254873,142.513,-22646.6
0.00185738,0.299932,135.653,-19825.8
0.00220762,0.346276,129.122,-17580.5
0.0025879,0.394155,122.797,-15769.4
0.00300291,0.443805,116.576,-14281.8
0.00345819,0.495445,110.37,-13031.5
0.00396027,0.549266,104.109,-11952
0.00451691,0.605417,97.7326,-10991.7
0.00513718,0.663983,91.196,-10111.6
0.00583107,0.724897,84.475,-9283.02
0.00660381,0.787484,77.615,-8490.92
0.00746954,0.851596,70.6061,-7718.17
0.00842416,0.915598,63.603,-6969.54
0.00947872,0.978936,56.6459,-6240.14
0.0106388,1.04061,49.8258,-5533.47
0.011883,1.0985,43.3637,-4868.33
0.0132313,1.15274,37.2335,-4239.6
0.0147009,1.2031,31.4491,-3647.36
0.0163095,1.24922,26.0396,-3093.86
0.0180714,1.29057,21.0516,-2583.46
0.019991,1.32652,16.5492,-2122.48
0.0220541,1.35645,12.6022,-1717.96
0.0242248,1.38004,9.25913,-1374.87
0.0263955,1.39713,6.58425,-1099.83
0.0286464,1.40937,4.37471,-872.107
0.0308973,1.41717,2.62324,-691.044
0.0331482,1.42145,1.23597,-547.086
0.0353991,1.42295,0.138271,-432.631
0.0370963,1.42259,-0.53445,-362.121
0.0389065,1.42107,-1.13125,-299.218
0.0407829,1.41845,-1.64041,-245.174
0.0428442,1.41459,-2.09396,-196.59
0.0450799,1.40945,-2.48434,-154.252
0.0470669,1.40423,-2.75969,-123.928
0.0490539,1.39852,-2.9805,-99.1712
0.0510409,1.39242,-3.15679,-78.9617
0.0527256,1.38699,-3.2775,-64.7601
0.054495,1.3811,-3.38069,-52.2584
0.0564728,1.37432,-3.47224,-40.7206
0.0585481,1.36703,-3.54617,-30.8839
0.0601649,1.36126,-3.59082,-24.5408
0.0619483,1.35482,-3.62919,-18.6661
0.0640128,1.34729,-3.66175,-13.087
0.0660773,1.33971,-3.68394,-8.57967
0.0676376,1.33395,-3.69505,-5.74967
0.0693893,1.32747,-3.70271,-3.07693
0.0714865,1.3197,-3.70631,-0.459119
0.0733182,1.31291,-3.70538,1.40416
0.0752658,1.3057,-3.701,3.02727
0.0772134,1.2985,-3.69376,4.34762
0.079161,1.29132,-3.6842,5.41957
0.0808068,1.28526,-3.67464,6.17139
0.0825421,1.27889,-3.66333,6.82847
0.084531,1.27162,-3.64911,7.43932
0.0866488,1.26391,-3.63278,7.95224
0.0881542,1.25845,-3.62057,8.2566
0.0899043,1.25213,-3.60585,8.54398
0.0920617,1.24437,-3.5871,8.82015
0.0938214,1.23807,-3.57141,8.99878
0.0957623,1.23115,-3.55378,9.15072
0.0978091,1.2239,-3.53491,9.26882
0.0994555,1.21809,-3.51958,9.34545
0.1,1.21618,-3.51449,9.36755
Pimodel-based best: 
t,x,xDot,xDotDot
0,0,200,-32453.2
0.000206288,0.0405816,193.516,-30421.6
0.000588812,0.112469,182.568,-26873.8
0.000971336,0.180419,172.905,-23720.9
0.00138731,0.25038,163.667,-20780.2
0.00182752,0.320501,155.108,-18189.6
0.00229556,0.391192,147.138,-15945.7
0.00279445,0.462697,139.68,-14029.1
0.0033277,0.535269,132.648,-12407
0.00389936,0.60915,125.962,-11040.3
0.00451415,0.684581,119.543,-9888.47
0.00517763,0.761795,113.319,-8912.65
0.00589643,0.841022,107.224,-8077.44
0.00667851,0.922488,101.201,-7351.99
0.0075335,1.00641,95.1988,-6710.33
0.00847313,1.09299,89.1742,-6131.26
0.00951171,1.1824,83.0914,-5598.02
0.0106667,1.27475,76.9226,-5097.79
0.0119591,1.37004,70.6501,-4621.27
0.0134138,1.4681,64.27,-4162.28
0.0150523,1.56802,57.8227,-3719.13
0.0168929,1.6684,51.3797,-3292.8
0.0189749,1.76854,44.964,-2881.48
0.0212796,1.86488,38.7807,-2495.05
0.0236872,1.95136,33.1967,-2152.78
0.0262374,2.02936,28.1096,-1845.29
0.0289517,2.09922,23.4871,-1568.63
0.0318466,2.161,19.3157,-1320.65
0.0349325,2.21468,15.591,-1100.19
0.0382104,2.26024,12.3122,-906.608
0.041668,2.29775,9.47649,-739.391
0.0447717,2.3238,7.37936,-615.752
0.0465175,2.33578,6.35781,-555.527
0.0488685,2.34926,5.13829,-483.587
0.0520367,2.36326,3.74092,-401.075
0.0535575,2.3685,3.15755,-366.608
0.0557171,2.37449,2.41429,-322.644
0.058715,2.38036,1.52803,-270.138
0.0605192,2.3827,1.06583,-242.715
0.0628892,2.38457,0.529261,-210.822
0.0658903,2.38527,-0.0501314,-176.296
0.0675367,2.38495,-0.326562,-159.786
0.0696922,2.38389,-0.649691,-140.438
0.0727333,2.3813,-1.04006,-116.979
0.0751059,2.37852,-1.29865,-101.37
0.0778822,2.37455,-1.55769,-85.6544
0.0802033,2.37071,-1.74308,-74.3438
0.0826662,2.3662,-1.91303,-63.9097
0.085271,2.36102,-2.0668,-54.3947
0.0878758,2.35546,-2.19759,-46.2258
0.0899252,2.35086,-2.28648,-40.6243
0.0921726,2.34562,-2.37156,-35.2053
0.0948746,2.33909,-2.45887,-29.5662
0.097303,2.33304,-2.52525,-25.2073
0.0998746,2.32647,-2.58483,-21.2191
0.1,2.32614,-2.58748,-21.0402
Explicit-based best: 
t,x,xDot,xDotDot
0,0,200,-12072.1
0.0002,0.0397583,197.583,-12061.2
0.00052524,0.103387,193.705,-11747.6
0.00086494,0.16852,189.796,-11247.2
0.00123599,0.238184,185.733,-10657.6
0.00164205,0.31274,181.531,-10048.6
0.00208961,0.393,177.169,-9458.35
0.00258646,0.479882,172.611,-8904.86
0.00314239,0.574494,167.808,-8392.62
0.0037698,0.678159,162.696,-7918.14
0.00448454,0.792461,157.2,-7474.04
0.00530707,0.919284,151.232,-7051.81
0.00623981,1.05734,144.846,-6652.7
0.00730081,1.20735,137.996,-6270.29
0.00852352,1.37149,130.564,-5895.52
0.00994458,1.5512,122.458,-5521.65
0.0115996,1.74649,113.64,-5143.94
0.0135036,1.95377,104.216,-4762.46
0.0155523,2.15755,94.8407,-4396.88
0.0178171,2.36139,85.3016,-4033.05
0.0203487,2.56482,75.5644,-3665.88
0.0232111,2.76662,65.6153,-3292.29
0.0246964,2.86051,60.8591,-3113.79
0.0269123,2.98794,54.2386,-2864.92
0.0289498,3.09265,48.6197,-2653.21
0.0312691,3.19848,42.7279,-2430.46
0.0327094,3.25754,39.3209,-2301.37
0.0344994,3.32432,35.3384,-2149.96
0.0368179,3.40064,30.5677,-1967.82
0.0385465,3.45061,27.2764,-1841.66
0.0405473,3.50159,23.7298,-1705.12
0.0427666,3.55017,20.1033,-1564.78
0.0443298,3.57972,17.7301,-1472.53
0.0461412,3.60948,15.1548,-1371.94
0.0483588,3.63981,12.241,-1257.43
0.0501367,3.65963,10.082,-1172.08
0.0520968,3.6772,7.87182,-1084.13
0.0541981,3.69141,5.68694,-996.561
0.0558575,3.6995,4.08734,-931.995
0.0576571,3.70539,2.46989,-866.239
0.0597157,3.70869,0.759766,-796.123
0.0615218,3.70879,-0.625812,-738.799
0.063328,3.70649,-1.9112,-685.137
0.0653293,3.70133,-3.22619,-629.673
0.0676656,3.69213,-4.62644,-569.863
0.069518,3.6826,-5.64096,-525.959
0.0715322,3.67021,-6.65505,-481.491
0.0737179,3.65455,-7.65797,-436.824
0.0755724,3.63961,-8.4351,-401.656
0.0775201,3.62245,-9.18348,-367.226
0.0796152,3.60243,-9.9164,-332.856
0.0817102,3.58094,-10.5801,-301.057
0.0835039,3.5615,-11.0971,-275.747
0.0853796,3.54021,-11.5909,-251.025
0.0874632,3.51553,-12.087,-225.517
0.0896366,3.48875,-12.5501,-200.944
0.0913093,3.46748,-12.8714,-183.375
0.0931671,3.44327,-13.195,-165.108
0.0953641,3.4139,-13.5354,-145.092
0.097288,3.3876,-13.7988,-128.893
0.0993238,3.35925,-14.0449,-112.994
0.1,3.34973,-14.1196,-107.993