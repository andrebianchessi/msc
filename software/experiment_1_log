## Training model from 0 to 0.025 ##
## Training initial conditions ##
Loss: 144.054
Loss: 46.4307
Loss: 12.4413
Loss: 4.03196
Loss: 1.78771
Loss: 1.57568
Loss: 1.30932
Loss: 1.23114
Loss: 1.1717
Loss: 1.0675
Loss: 1.05538
Loss: 0.997222
Loss: 0.890927
Loss: 0.912138
Loss: 0.807672
Loss: 0.732836
Loss: 0.74454
Loss: 0.705426
Loss: 0.635257
Loss: 0.61549
## Training physics ##
Loss: 6512.23
Loss: 3137.56
Loss: 2112.68
Loss: 1435.51
Loss: 1047.35
Loss: 839.715
Loss: 729.651
Loss: 589.919
Loss: 442.044
Loss: 383.788
Loss: 321.277
Loss: 289.221
Loss: 250.707
Loss: 208.444
Loss: 185.607
Loss: 164.924
Loss: 152.14
Loss: 140.794
Loss: 130.792
Loss: 123.209

## Training model from 0.025 to 0.05 ##
## Training initial conditions ##
Loss: 376.256
Loss: 273.088
Loss: 219.669
Loss: 188.028
Loss: 155.168
Loss: 132.128
Loss: 111.303
Loss: 92.2829
Loss: 78.1587
Loss: 63.9247
Loss: 54.8834
Loss: 46.2575
Loss: 39.7679
Loss: 33.1486
Loss: 28.6921
Loss: 25.6446
Loss: 21.8576
Loss: 18.5744
Loss: 16.072
Loss: 13.32
## Training physics ##
Loss: 1422.56
Loss: 790.486
Loss: 634.479
Loss: 527.629
Loss: 462.872
Loss: 779.286
Loss: 360.402
Loss: 319.459
Loss: 267.486
Loss: 254.586
Loss: 217.637
Loss: 200.645
Loss: 187.246
Loss: 184.263
Loss: 160.992
Loss: 150.48
Loss: 146.65
Loss: 138.865
Loss: 132.55
Loss: 123.899

## Training model from 0.05 to 0.075 ##
## Training initial conditions ##
Loss: 788.165
Loss: 650.9
Loss: 535.485
Loss: 472.682
Loss: 394.647
Loss: 333.734
Loss: 287.934
Loss: 241.535
Loss: 205.118
Loss: 174.764
Loss: 145.171
Loss: 119.618
Loss: 101.815
Loss: 86.7972
Loss: 74.1852
Loss: 64.0953
Loss: 54.2401
Loss: 45.6003
Loss: 38.595
Loss: 32.4589
## Training physics ##
Loss: 991.406
Loss: 641.988
Loss: 378.097
Loss: 286.111
Loss: 232.485
Loss: 200.575
Loss: 148.025
Loss: 125.191
Loss: 113.223
Loss: 99.7824
Loss: 87.6595
Loss: 77.9686
Loss: 72.697
Loss: 67.9509
Loss: 62.2878
Loss: 56.2764
Loss: 53.3996
Loss: 51.5902
Loss: 49.5053
Loss: 45.9881

## Training model from 0.075 to 0.1 ##
## Training initial conditions ##
Loss: 979.296
Loss: 826.262
Loss: 676.64
Loss: 588.861
Loss: 504.84
Loss: 430.05
Loss: 359.059
Loss: 294.778
Loss: 254.073
Loss: 214.42
Loss: 178.526
Loss: 153.129
Loss: 129.768
Loss: 111.991
Loss: 95.0682
Loss: 81.3781
Loss: 66.5432
Loss: 56.9304
Loss: 47.609
Loss: 40.2756
## Training physics ##
Loss: 497.669
Loss: 344.712
Loss: 253.081
Loss: 205.345
Loss: 162.671
Loss: 136.749
Loss: 116.396
Loss: 102.944
Loss: 91.0798
Loss: 83.9294
Loss: 74.3292
Loss: 69.7535
Loss: 64.2205
Loss: 59.2239
Loss: 52.7037
Loss: 48.1339
Loss: 44.8219
Loss: 42.0629
Loss: 37.7619
Loss: 35.4351

Time to train models: 15442617 us
generation,cost
0,57367.6
1,55013
Time to G.A. optimization using Pimodels: 977693 us
generation,cost
0,4.15684e+06
1,2.60167e+06
2,2.06368e+06
3,1.86995e+06
4,1.73634e+06
5,1.65949e+06
Time to G.A. optimization using Explicit integration: 37083042 us
Random solution: 
t,x,xDot,xDotDot
0,0,200,-106868
0.000169388,0.0324547,183.804,-85406.8
0.000338776,0.062446,170.762,-69355.4
0.000520606,0.0924252,159.377,-56507.1
0.000711128,0.121829,149.608,-46553.6
0.000911926,0.150988,141.076,-38822.3
0.00112448,0.180145,133.497,-32799.7
0.00135052,0.209526,126.643,-28080.2
0.00159209,0.23934,120.333,-24345.6
0.00185162,0.269786,114.422,-21348.4
0.00213202,0.301065,108.795,-18897.9
0.00243683,0.333383,103.36,-16849.5
0.00277039,0.366956,98.0438,-15095.6
0.00313805,0.402019,92.7869,-13557.9
0.00354639,0.438818,87.5415,-12181.3
0.00400348,0.477605,82.2696,-10929
0.00451879,0.518603,76.9443,-9778.1
0.00510269,0.561926,71.5556,-8716.63
0.00574152,0.605927,66.2992,-7772.15
0.00642934,0.649759,61.2483,-6942.37
0.00717381,0.693505,56.3629,-6206.19
0.0079814,0.737074,51.6248,-5548.53
0.00885869,0.780308,47.0248,-4956.82
0.00981212,0.822975,42.5619,-4420.65
0.0108481,0.864788,38.2428,-3931.38
0.0119733,0.90543,34.0789,-3482.01
0.0131953,0.944579,30.0844,-3067.05
0.0145228,0.981933,26.2748,-2682.42
0.0159669,1.01721,22.6658,-2325.4
0.0175403,1.05013,19.2746,-1994.51
0.0192565,1.08043,16.1208,-1689.5
0.0211272,1.1078,13.2285,-1411.26
0.0231569,1.13193,10.6257,-1161.61
0.0253364,1.15251,8.3408,-942.77
0.0276384,1.16938,6.39304,-756.319
0.0300224,1.18263,4.78091,-601.993
0.0324064,1.19244,3.49779,-479.117
0.0347904,1.19952,2.47664,-381.272
0.0360283,1.2023,2.0316,-338.594
0.0376947,1.20524,1.51016,-288.566
0.0397127,1.20774,0.980771,-237.732
0.0413251,1.20902,0.625669,-203.594
0.0430582,1.20982,0.300683,-172.317
0.0448512,1.2101,0.0169321,-144.969
0.0466443,1.20991,-0.22175,-121.925
0.0484373,1.20932,-0.422456,-102.506
0.0500427,1.20852,-0.574849,-87.7271
0.0516481,1.20749,-0.705245,-75.0484
0.0534624,1.20609,-0.830046,-62.8754
0.0554365,1.20434,-0.942909,-51.8211
0.0570235,1.20278,-1.01905,-44.3256
0.0587411,1.20097,-1.08907,-37.3971
0.06064,1.19884,-1.15377,-30.9519
0.0625389,1.19659,-1.20728,-25.5764
0.0640338,1.19476,-1.24276,-21.9759
0.0656725,1.1927,-1.27591,-18.5788
0.0675955,1.19021,-1.3083,-15.2161
0.0693563,1.18789,-1.33275,-12.6336
0.0711818,1.18543,-1.35369,-10.3782
0.0730073,1.18295,-1.37085,-8.48401
0.0745972,1.18076,-1.38319,-7.08063
0.0762453,1.17847,-1.3938,-5.83507
0.0780719,1.17591,-1.40336,-4.66672
0.0799924,1.17321,-1.4113,-3.6409
0.0815092,1.17107,-1.41628,-2.95026
0.0831715,1.16871,-1.42063,-2.30165
0.0850929,1.16597,-1.42443,-1.67137
0.0870143,1.16323,-1.42711,-1.14805
0.0884725,1.16115,-1.42853,-0.806053
0.0901064,1.15882,-1.42957,-0.477779
0.0920656,1.15602,-1.43017,-0.148028
0.0937701,1.15358,-1.4302,0.0938241
0.0955883,1.15098,-1.42982,0.31085
0.0974064,1.14838,-1.42908,0.492853
0.0992245,1.14578,-1.42804,0.645332
0.1,1.14467,-1.42751,0.706598
Pimodel-based best: 
t,x,xDot,xDotDot
0,0,200,-72689
0.0002,0.0386087,186.388,-63671.5
0.000549997,0.100222,166.435,-50926.2
0.000899993,0.155566,150.388,-41201.6
0.00127023,0.208613,136.651,-33369.1
0.00165506,0.258892,125.05,-27212.9
0.0020568,0.307073,115.136,-22372.2
0.00247769,0.353672,106.559,-18566.8
0.00292026,0.399119,99.0361,-15573.2
0.0033874,0.443774,92.3392,-13214.1
0.00388235,0.487941,86.2831,-11348.1
0.00440886,0.531871,80.718,-9862.94
0.0049712,0.57577,75.5228,-8669.72
0.00557433,0.619806,70.6,-7698.11
0.00622398,0.664107,65.8715,-6892.84
0.00692685,0.708763,61.2759,-6210.73
0.00769076,0.753821,56.7657,-5618.36
0.00852493,0.799282,52.3064,-5090.22
0.00944022,0.845096,47.8748,-4607.21
0.0104495,0.891149,43.4587,-4155.44
0.0115681,0.937256,39.0568,-3725.38
0.0128144,0.983148,34.6784,-3311.06
0.0142098,1.02845,30.345,-2909.65
0.0157791,1.07265,26.0917,-2521.09
0.0175353,1.11479,21.9984,-2150.45
0.0194905,1.15392,18.1435,-1803.38
0.0216491,1.18914,14.6045,-1485.97
0.0239839,1.21946,11.4735,-1205.88
0.0264422,1.24427,8.81201,-968.187
0.0289005,1.26321,6.67489,-777.516
0.0313587,1.27743,4.95856,-624.448
0.033817,1.28787,3.58013,-501.501
0.0362753,1.29526,2.47315,-402.71
0.0387336,1.3002,1.58433,-323.305
0.0411918,1.30319,0.870879,-259.467
0.0436501,1.3046,0.298422,-208.137
0.0461084,1.30475,-0.160656,-166.858
0.0485666,1.30389,-0.528554,-133.661
0.0510249,1.30221,-0.823119,-106.96
0.0534832,1.29989,-1.0587,-85.484
0.0561354,1.2968,-1.25995,-67.0003
0.0589807,1.29297,-1.42754,-51.4504
0.0620206,1.28841,-1.56361,-38.6432
0.0652622,1.28316,-1.6713,-28.2987
0.0687167,1.27723,-1.75418,-20.1001
0.0724,1.27065,-1.81584,-13.7253
0.0763323,1.26342,-1.8597,-8.86605
0.0805396,1.25553,-1.8889,-5.24002
0.0850538,1.24696,-1.90619,-2.59642
0.0899146,1.23767,-1.91392,-0.718554
0.0951713,1.22761,-1.91403,0.576207
0.1,1.21837,-1.90929,1.33183
Explicit-based best: 
t,x,xDot,xDotDot
0,0,200,-14447.6
0.000244377,0.0484468,196.505,-14145
0.00067173,0.131151,190.598,-13480.1
0.00109908,0.211395,184.992,-12751.8
0.0015747,0.297969,179.119,-11952.4
0.00208603,0.38803,173.214,-11155.1
0.00264093,0.482469,167.243,-10384.4
0.00324647,0.581885,161.181,-9656.17
0.00391152,0.686995,154.991,-8977.61
0.00464676,0.798583,148.628,-8349.89
0.00546509,0.917481,142.04,-7770.11
0.00638175,1.0445,135.171,-7232.71
0.0074142,1.18029,127.971,-6730.6
0.00858129,1.32518,120.401,-6256.09
0.00990178,1.47885,112.448,-5801.73
0.0113931,1.64026,104.132,-5360.93
0.0130579,1.80639,95.5722,-4931.72
0.014865,1.97128,87.0395,-4519.52
0.0168592,2.13615,78.4391,-4113.5
0.0190841,2.30083,69.7461,-3708.47
0.0215958,2.46475,60.953,-3301.51
0.0244651,2.62663,52.0806,-2891.94
0.0277778,2.78407,43.1968,-2481.92
0.0316169,2.93266,34.4657,-2078.35
0.0338823,3.00558,29.9959,-1871.37
0.0367448,3.08411,24.9794,-1638.59
0.0385037,3.12558,22.2119,-1509.96
0.0407058,3.17095,19.0516,-1362.77
0.0434179,3.21781,15.58,-1200.65
0.0450969,3.24232,13.6412,-1109.92
0.0471828,3.26844,11.4357,-1006.43
0.0498455,3.29546,8.91687,-887.845
0.0517182,3.31065,7.3256,-812.683
0.0538892,3.3247,5.64892,-733.209
0.0564166,3.33673,3.90285,-650.078
0.0582368,3.34279,2.76956,-595.891
0.0603101,3.34729,1.59358,-539.409
0.0627754,3.34964,0.339803,-478.85
0.0646495,3.34946,-0.51799,-437.173
0.0667025,3.34751,-1.37198,-395.434
0.0692385,3.34281,-2.31479,-349.001
0.0716509,3.33625,-3.10829,-309.56
0.0742156,3.3273,-3.85332,-272.14
0.0760893,3.31962,-4.33976,-247.46
0.078223,3.30982,-4.83996,-221.815
0.0808239,3.29651,-5.3797,-193.762
0.0829453,3.28468,-5.76863,-173.24
0.0852772,3.27077,-6.14845,-152.872
0.0877455,3.25515,-6.50153,-133.562
0.0897348,3.24196,-6.75306,-119.528
0.0918881,3.22716,-6.99533,-105.717
0.0943372,3.20972,-7.23662,-91.5849
0.0967863,3.19174,-7.4452,-78.9635
0.0986911,3.17742,-7.58706,-70.1013
0.1,3.16743,-7.67508,-64.4495